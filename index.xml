<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>s3m</title>
    <link>https://s3m.stream/</link>
    <description>Recent content on s3m</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    
	<atom:link href="https://s3m.stream/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>s3m</title>
      <link>https://s3m.stream/about/</link>
      <pubDate>Fri, 05 Apr 2019 20:50:30 +0200</pubDate>
      
      <guid>https://s3m.stream/about/</guid>
      <description>Problem trying to solve There are streams of data that can not be lost besides that when created, they degrade the performance of running systems, for example, if the stream is a backup of a database, every time the stream is produced it may lock the entire cluster (depends on the options and tools used mysqldump/xtrabackup for example), however, the effort to create the stream is proportional to the size of the database, in most of the cases the bigger the database is the more time and CPU and Memory is required.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://s3m.stream/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://s3m.stream/readme/</guid>
      <description>public www public content</description>
    </item>
    
  </channel>
</rss>